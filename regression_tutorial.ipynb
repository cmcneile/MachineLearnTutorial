{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression example with a neural network\n",
    "\n",
    "\n",
    "This example is taken from: https://www.tensorflow.org/tutorials/keras/basic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IO section\n",
    "Get the data set and clean it up\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
      "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
      "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
      "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
      "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
      "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
      "\n",
      "     Model Year  Origin  \n",
      "393          82       1  \n",
      "394          82       2  \n",
      "395          82       1  \n",
      "396          82       1  \n",
      "397          82       1  \n"
     ]
    }
   ],
   "source": [
    "##dataset_path = keras.utils.get_file(\"auto-mpg.data\", r\"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-m\n",
    "\n",
    "\n",
    "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"httpsarchive.ics.uci.autom\")\n",
    "\n",
    "\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin'] \n",
    "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      sep=\" \", skipinitialspace=True)\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "print(dataset.tail() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPG             0\n",
      "Cylinders       0\n",
      "Displacement    0\n",
      "Horsepower      6\n",
      "Weight          0\n",
      "Acceleration    0\n",
      "Model Year      0\n",
      "Origin          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.isna().sum())\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "origin = dataset.pop('Origin')\n",
    "\n",
    "dataset['USA'] = (origin == 1)*1.0\n",
    "dataset['Europe'] = (origin == 2)*1.0\n",
    "dataset['Japan'] = (origin == 3)*1.0\n",
    "dataset.tail()\n",
    "\n",
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              count         mean         std     min      25%     50%  \\\n",
      "Cylinders     314.0     5.477707    1.699788     3.0     4.00     4.0   \n",
      "Displacement  314.0   195.318471  104.331589    68.0   105.50   151.0   \n",
      "Horsepower    314.0   104.869427   38.096214    46.0    76.25    94.5   \n",
      "Weight        314.0  2990.251592  843.898596  1649.0  2256.50  2822.5   \n",
      "Acceleration  314.0    15.559236    2.789230     8.0    13.80    15.5   \n",
      "Model Year    314.0    75.898089    3.675642    70.0    73.00    76.0   \n",
      "USA           314.0     0.624204    0.485101     0.0     0.00     1.0   \n",
      "Europe        314.0     0.178344    0.383413     0.0     0.00     0.0   \n",
      "Japan         314.0     0.197452    0.398712     0.0     0.00     0.0   \n",
      "\n",
      "                  75%     max  \n",
      "Cylinders        8.00     8.0  \n",
      "Displacement   265.75   455.0  \n",
      "Horsepower     128.00   225.0  \n",
      "Weight        3608.00  5140.0  \n",
      "Acceleration    17.20    24.8  \n",
      "Model Year      79.00    82.0  \n",
      "USA              1.00     1.0  \n",
      "Europe           0.00     1.0  \n",
      "Japan            0.00     1.0  \n"
     ]
    }
   ],
   "source": [
    "#train_labels = train_dataset.pop('MPG')\n",
    "#test_labels = test_dataset.pop('MPG')\n",
    "\n",
    "\n",
    "\n",
    "train_stats = train_dataset.describe()\n",
    "train_stats.pop(\"MPG\")\n",
    "train_stats = train_stats.transpose()\n",
    "print(train_stats)\n",
    "\n",
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')\n",
    "\n",
    "\n",
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_labels = train_dataset.pop('MPG')\n",
    "#test_labels = test_dataset.pop('MPG')\n",
    "\n",
    "\n",
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train_dataset.keys())]),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mean_squared_error',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "  return model\n",
    "\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3caefa261807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "#history = model.fit(normed_train_data, train_labels,epochs=EPOCHS, validation_split = 0.2, verbose=0)\n",
    "\n",
    "history = model.fit(normed_train_data, train_labels,epochs=EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
